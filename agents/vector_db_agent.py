"""
Vector Database Agent - RAG System
===================================
Agent quáº£n lÃ½ Vector Database cho semantic search
Sá»­ dá»¥ng ChromaDB + OpenAI Embeddings
"""

import chromadb
from chromadb.config import Settings
import pandas as pd
from typing import List, Dict, Any, Optional
import os
from pathlib import Path
import json
import unicodedata


class VectorDatabaseAgent:
    """Agent quáº£n lÃ½ Vector Database vá»›i ChromaDB"""
    
    # City name mapping (Vietnamese with diacritics -> English)
    # Bao gá»“m 64 tá»‰nh thÃ nh Viá»‡t Nam
    CITY_MAP = {
        # ThÃ nh phá»‘ lá»›n
        'hÃ  ná»™i': 'Hanoi',
        'há»“ chÃ­ minh': 'Ho Chi Minh City',
        'tp há»“ chÃ­ minh': 'Ho Chi Minh City',
        'tp.hcm': 'Ho Chi Minh City',
        'sÃ i gÃ²n': 'Ho Chi Minh City',
        'Ä‘Ã  náºµng': 'Da Nang',
        'háº£i phÃ²ng': 'Hai Phong',
        'cáº§n thÆ¡': 'Can Tho',
        
        # Miá»n Báº¯c
        'hÃ  giang': 'Ha Giang',
        'cao báº±ng': 'Cao Bang',
        'lÃ o cai': 'Lao Cai',
        'sapa': 'Sapa',
        'Ä‘iá»‡n biÃªn': 'Dien Bien',
        'lai chÃ¢u': 'Lai Chau',
        'sÆ¡n la': 'Son La',
        'yÃªn bÃ¡i': 'Yen Bai',
        'hoÃ  bÃ¬nh': 'Hoa Binh',
        'thÃ¡i nguyÃªn': 'Thai Nguyen',
        'láº¡ng sÆ¡n': 'Lang Son',
        'quáº£ng ninh': 'Quang Ninh',
        'háº¡ long': 'Ha Long',
        'cÃ¡t bÃ ': 'Cat Ba',
        'báº¯c giang': 'Bac Giang',
        'phÃº thá»': 'Phu Tho',
        'vÄ©nh phÃºc': 'Vinh Phuc',
        'báº¯c ninh': 'Bac Ninh',
        'háº£i dÆ°Æ¡ng': 'Hai Duong',
        'hÆ°ng yÃªn': 'Hung Yen',
        'thÃ¡i bÃ¬nh': 'Thai Binh',
        'hÃ  nam': 'Ha Nam',
        'nam Ä‘á»‹nh': 'Nam Dinh',
        'ninh bÃ¬nh': 'Ninh Binh',
        'tam Ä‘áº£o': 'Tam Dao',
        'ba vÃ¬': 'Ba Vi',
        'tuyÃªn quang': 'Tuyen Quang',
        'báº¯c káº¡n': 'Bac Kan',
        
        # Miá»n Trung
        'thanh hÃ³a': 'Thanh Hoa',
        'nghá»‡ an': 'Nghe An',
        'hÃ  tÄ©nh': 'Ha Tinh',
        'quáº£ng bÃ¬nh': 'Quang Binh',
        'quáº£ng trá»‹': 'Quang Tri',
        'huáº¿': 'Hue',
        'thá»«a thiÃªn huáº¿': 'Thua Thien Hue',
        'Ä‘Ã  náºµng': 'Da Nang',
        'quáº£ng nam': 'Quang Nam',
        'há»™i an': 'Hoi An',
        'quáº£ng ngÃ£i': 'Quang Ngai',
        'bÃ¬nh Ä‘á»‹nh': 'Binh Dinh',
        'quy nhÆ¡n': 'Quy Nhon',
        'phÃº yÃªn': 'Phu Yen',
        'khÃ¡nh hÃ²a': 'Khanh Hoa',
        'nha trang': 'Nha Trang',
        'ninh thuáº­n': 'Ninh Thuan',
        'bÃ¬nh thuáº­n': 'Binh Thuan',
        'phan thiáº¿t': 'Phan Thiet',
        'mÅ©i nÃ©': 'Mui Ne',
        
        # TÃ¢y NguyÃªn
        'kon tum': 'Kon Tum',
        'gia lai': 'Gia Lai',
        'Ä‘áº¯k láº¯k': 'Dak Lak',
        'Ä‘Äƒk lÄƒk': 'Dak Lak',
        'Ä‘áº¯k nÃ´ng': 'Dak Nong',
        'Ä‘Äƒk nÃ´ng': 'Dak Nong',
        'lÃ¢m Ä‘á»“ng': 'Lam Dong',
        'Ä‘Ã  láº¡t': 'Da Lat',
        
        # Miá»n Nam
        'bÃ¬nh phÆ°á»›c': 'Binh Phuoc',
        'tÃ¢y ninh': 'Tay Ninh',
        'bÃ¬nh dÆ°Æ¡ng': 'Binh Duong',
        'Ä‘á»“ng nai': 'Dong Nai',
        'bÃ  rá»‹a - vÅ©ng tÃ u': 'Ba Ria - Vung Tau',
        'ba ria vung tau': 'Ba Ria - Vung Tau',
        'vÅ©ng tÃ u': 'Vung Tau',
        'cÃ´n Ä‘áº£o': 'Con Dao',
        'long an': 'Long An',
        'tiá»n giang': 'Tien Giang',
        'báº¿n tre': 'Ben Tre',
        'trÃ  vinh': 'Tra Vinh',
        'vÄ©nh long': 'Vinh Long',
        'Ä‘á»“ng thÃ¡p': 'Dong Thap',
        'an giang': 'An Giang',
        'kiÃªn giang': 'Kien Giang',
        'cáº§n thÆ¡': 'Can Tho',
        'háº­u giang': 'Hau Giang',
        'sÃ³c trÄƒng': 'Soc Trang',
        'báº¡c liÃªu': 'Bac Lieu',
        'cÃ  mau': 'Ca Mau',
        'phÃº quá»‘c': 'Phu Quoc',
    }
    
    def __init__(self, persist_directory: str = "vector_db"):
        """
        Initialize Vector Database Agent
        
        Args:
            persist_directory: ThÆ° má»¥c lÆ°u trá»¯ vector database
        """
        self.persist_dir = Path(persist_directory)
        self.persist_dir.mkdir(exist_ok=True)
        
        # Initialize ChromaDB client
        self.client = chromadb.PersistentClient(
            path=str(self.persist_dir),
            settings=Settings(anonymized_telemetry=False)
        )
        
        # Collection name
        self.collection_name = "vietnam_places"
        
        # Get or create collection
        try:
            self.collection = self.client.get_collection(name=self.collection_name)
            print(f"âœ… Loaded existing collection: {self.collection_name}")
            print(f"   Documents: {self.collection.count()}")
        except:
            print(f"ğŸ“¦ Creating new collection: {self.collection_name}")
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"hnsw:space": "cosine"}
            )
    
    def add_places_from_csv(self, csv_path: str, batch_size: int = 100):
        """
        ThÃªm places tá»« CSV vÃ o Vector Database
        
        Args:
            csv_path: Path Ä‘áº¿n CSV file
            batch_size: Sá»‘ lÆ°á»£ng documents má»—i batch
        """
        print(f"ğŸ“¥ Loading data from {csv_path}...")
        
        try:
            df = pd.read_csv(csv_path)
            print(f"   Found {len(df)} places")
            
            # Prepare data
            documents = []
            metadatas = []
            ids = []
            
            for idx, row in df.iterrows():
                # Create document text (for embedding)
                doc_text = self._create_document_text(row)
                
                # Create metadata
                metadata = {
                    'name': str(row.get('name', '')),
                    'city': str(row.get('city', '')),
                    'category': str(row.get('category', '')),
                    'rating': float(row.get('rating', 0)),
                    'price': float(row.get('price', 0)),
                    'price_level': int(row.get('price_level', 0)),
                    'latitude': float(row.get('latitude', 0)) if pd.notna(row.get('latitude')) else None,
                    'longitude': float(row.get('longitude', 0)) if pd.notna(row.get('longitude')) else None,
                    'description': str(row.get('description', ''))[:500]  # Limit length
                }
                
                documents.append(doc_text)
                metadatas.append(metadata)
                ids.append(f"place_{idx}")
                
                # Add batch when reached batch_size
                if len(documents) >= batch_size:
                    self.collection.add(
                        documents=documents,
                        metadatas=metadatas,
                        ids=ids
                    )
                    print(f"   âœ… Added batch: {len(ids)} documents")
                    documents, metadatas, ids = [], [], []
            
            # Add remaining documents
            if documents:
                self.collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids
                )
                print(f"   âœ… Added final batch: {len(ids)} documents")
            
            print(f"âœ… Successfully added {df.shape[0]} places to vector database")
            
        except Exception as e:
            print(f"âŒ Error adding places: {e}")
    
    def _normalize_city_name(self, city: str) -> str:
        """Normalize city name to match database format"""
        if not city:
            return city
        
        # Try exact mapping first
        city_lower = city.lower().strip()
        if city_lower in self.CITY_MAP:
            return self.CITY_MAP[city_lower]
        
        # Return as-is if no mapping found
        return city
    
    def _create_document_text(self, row: pd.Series) -> str:
        """Táº¡o text document tá»« row data"""
        parts = []
        
        # Name
        if pd.notna(row.get('name')):
            parts.append(f"TÃªn: {row['name']}")
        
        # City
        if pd.notna(row.get('city')):
            parts.append(f"ThÃ nh phá»‘: {row['city']}")
        
        # Category
        if pd.notna(row.get('category')):
            parts.append(f"Loáº¡i: {row['category']}")
        
        # Description
        if pd.notna(row.get('description')):
            parts.append(f"MÃ´ táº£: {row['description']}")
        
        # Rating
        if pd.notna(row.get('rating')):
            parts.append(f"ÄÃ¡nh giÃ¡: {row['rating']}/5.0")
        
        return ". ".join(parts)
    
    def semantic_search(
        self, 
        query: str, 
        n_results: int = 10,
        city_filter: Optional[str] = None,
        category_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Semantic search trong vector database
        
        Args:
            query: Query text
            n_results: Sá»‘ lÆ°á»£ng káº¿t quáº£
            city_filter: Lá»c theo thÃ nh phá»‘
            category_filter: Lá»c theo category
        
        Returns:
            List of matching places
        """
        try:
            # Build where clause for filtering
            # Note: Only use city_filter, let semantic search handle category matching
            where = None
            if city_filter:
                # Normalize city name
                normalized_city = self._normalize_city_name(city_filter)
                where = {"city": {"$eq": normalized_city}}
            
            # Query vector database
            results = self.collection.query(
                query_texts=[query],
                n_results=n_results,
                where=where
            )
            
            # Format results
            places = []
            if results and results['metadatas'] and len(results['metadatas'][0]) > 0:
                for i, metadata in enumerate(results['metadatas'][0]):
                    place = {
                        'name': metadata.get('name', ''),
                        'city': metadata.get('city', ''),
                        'category': metadata.get('category', ''),
                        'rating': metadata.get('rating', 0),
                        'price': metadata.get('price', 0),
                        'price_level': metadata.get('price_level', 0),
                        'description': metadata.get('description', ''),
                        'latitude': metadata.get('latitude'),
                        'longitude': metadata.get('longitude'),
                        'similarity_score': 1 - results['distances'][0][i] if results['distances'] else 0
                    }
                    places.append(place)
            
            return places
            
        except Exception as e:
            print(f"âŒ Error in semantic search: {e}")
            return []
    
    def get_recommendations(
        self,
        destination: str,
        interests: str,
        budget: int,
        days: int,
        travelers: int = 1,
        n_results: int = 20
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        Láº¥y recommendations cho travel plan
        
        Args:
            destination: Äiá»ƒm Ä‘áº¿n
            interests: Sá»Ÿ thÃ­ch
            budget: NgÃ¢n sÃ¡ch
            days: Sá»‘ ngÃ y
            travelers: Sá»‘ ngÆ°á»i Ä‘i
            n_results: Sá»‘ káº¿t quáº£ má»—i category
        
        Returns:
            Dict vá»›i hotels, restaurants, attractions
        """
        # Build search query
        query = f"Du lá»‹ch {destination}. Sá»Ÿ thÃ­ch: {interests}. NgÃ¢n sÃ¡ch: {budget} VND. {days} ngÃ y. {travelers} ngÆ°á»i."
        
        results = {
            'hotels': [],
            'restaurants': [],
            'attractions': []
        }
        
        # Search hotels (semantic search will understand "hotel" from query)
        results['hotels'] = self.semantic_search(
            query=f"KhÃ¡ch sáº¡n hotel resort táº¡i {destination}. NgÃ¢n sÃ¡ch {budget} VND. PhÃ¹ há»£p {travelers} ngÆ°á»i.",
            n_results=n_results,
            city_filter=destination
        )
        
        # Search restaurants (semantic search will understand "restaurant" from query)
        results['restaurants'] = self.semantic_search(
            query=f"NhÃ  hÃ ng restaurant quÃ¡n Äƒn táº¡i {destination}. áº¨m thá»±c {interests}. Äáº·c sáº£n Ä‘á»‹a phÆ°Æ¡ng.",
            n_results=n_results,
            city_filter=destination
        )
        
        # Search attractions (semantic search will understand "attraction" from query)
        results['attractions'] = self.semantic_search(
            query=f"Äiá»ƒm tham quan attraction du lá»‹ch táº¡i {destination}. Hoáº¡t Ä‘á»™ng {interests}. VÄƒn hÃ³a lá»‹ch sá»­.",
            n_results=n_results,
            city_filter=destination
        )
        
        return results
    
    def get_database_stats(self) -> Dict[str, Any]:
        """Láº¥y statistics cá»§a database"""
        try:
            count = self.collection.count()
            
            # Sample some documents to get city/category distribution
            sample = self.collection.get(limit=1000)
            
            cities = set()
            categories = set()
            
            if sample and sample['metadatas']:
                for metadata in sample['metadatas']:
                    if metadata.get('city'):
                        cities.add(metadata['city'])
                    if metadata.get('category'):
                        categories.add(metadata['category'])
            
            return {
                'total_documents': count,
                'cities': list(cities),
                'categories': list(categories),
                'collection_name': self.collection_name
            }
            
        except Exception as e:
            print(f"âŒ Error getting stats: {e}")
            return {}


# Global instance
vector_db_agent = None

def get_vector_db_agent() -> VectorDatabaseAgent:
    """Get singleton instance of Vector DB Agent"""
    global vector_db_agent
    if vector_db_agent is None:
        vector_db_agent = VectorDatabaseAgent()
    return vector_db_agent


# Test
if __name__ == "__main__":
    print("="*60)
    print("VECTOR DATABASE AGENT - TEST")
    print("="*60)
    
    # Initialize agent
    agent = VectorDatabaseAgent()
    
    # Get stats
    stats = agent.get_database_stats()
    print(f"\nğŸ“Š Database Stats:")
    print(f"   Total documents: {stats.get('total_documents', 0)}")
    print(f"   Cities: {len(stats.get('cities', []))}")
    print(f"   Categories: {len(stats.get('categories', []))}")
    
    # Test search
    print(f"\nğŸ” Testing semantic search...")
    results = agent.semantic_search("khÃ¡ch sáº¡n sang trá»ng á»Ÿ HÃ  Ná»™i", n_results=5, city_filter="HÃ  Ná»™i")
    print(f"   Found {len(results)} results")
    for i, place in enumerate(results[:3], 1):
        print(f"   {i}. {place['name']} - {place['city']} ({place['similarity_score']:.2f})")
    
    # Test recommendations
    print(f"\nğŸ¯ Testing recommendations...")
    recs = agent.get_recommendations(
        destination="HÃ  Ná»™i",
        interests="vÄƒn hÃ³a, áº©m thá»±c",
        budget=10000000,
        days=3,
        travelers=2
    )
    print(f"   Hotels: {len(recs['hotels'])}")
    print(f"   Restaurants: {len(recs['restaurants'])}")
    print(f"   Attractions: {len(recs['attractions'])}")
    
    print("\n" + "="*60)
    print("âœ… Test completed!")

